{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/cads-logo.png\" style=\"height: 100px;\" align=left> \n",
    "<img src=\"../images/sklearn-logo.png\" style=\"height: 100px;\" align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Thinking about Model Validation](#Thinking-about-Model-Validation)\n",
    "- [Cross Validation](#Cross-Validation)\n",
    "- [Model validation the wrong way](#Model-validation-the-wrong-way)\n",
    "    - [Question: Can you guess the result of the following cell?](#Question:-Can-you-guess-the-result-of-the-following-cell?)\n",
    "- [Model validation the right way: Holdout sets](#Model-validation-the-right-way:-Holdout-sets)\n",
    "- [Model validation via cross-validation](#Model-validation-via-cross-validation)\n",
    "- [Grid Search](#Grid-Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking about Model Validation\n",
    "\n",
    "In principle, model validation is very simple: after choosing a model and its hyperparameters, we can estimate how effective it is by applying it to some of the training data and comparing the prediction to the known value.\n",
    "\n",
    "The following sections first show a naive approach to model validation and why it\n",
    "fails, before exploring the use of holdout sets and cross-validation for more robust\n",
    "model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation the wrong way\n",
    "\n",
    "Let's demonstrate the naive approach to validation using the Iris data, which we saw in the previous section. We will start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (150, 4)\n",
      "Shape of y: (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print('Shape of X:', X.shape)\n",
    "print('Shape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we choose a model and hyperparameters. Here we'll use a *k*-neighbors classifier with ``n_neighbors=1``.\n",
    "This is a very simple and intuitive model that says \"the label of an unknown point is the same as the label of its closest training point:\"\n",
    "\n",
    "<img src='../images/KNN.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model= KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train the model, and use it to predict labels for data we already know:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the fraction of correctly labeled points:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Can you guess the result of the following cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an accuracy score of 1.0, which indicates that 100% of points were correctly labeled by our model!\n",
    "But is this truly measuring the expected accuracy? Have we really come upon a model that we expect to be correct 100% of the time?\n",
    "\n",
    "As you may have gathered, the answer is no.\n",
    "In fact, this approach contains a fundamental flaw: *it trains and evaluates the model on the same data*.\n",
    "Furthermore, the nearest neighbor model is an *instance-based* estimator that simply stores the training data, and predicts labels by comparing new data to these stored points: except in contrived cases, it will get 100% accuracy *every time!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation the right way: Holdout sets\n",
    "\n",
    "So what can be done?\n",
    "A better sense of a model's performance can be found using what's known as a *holdout set*: that is, we hold back some subset of the data from the training of the model, and then use this holdout set to check the model performance.\n",
    "This splitting can be done using the ``train_test_split`` utility in Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data with 50% in each set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0,train_size=0.5)\n",
    "\n",
    "#fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# fit and evaluate the model on the second set of data\n",
    "y_model = model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here a more reasonable result: the nearest-neighbor classifier is about 90% accurate on this hold-out set.\n",
    "The hold-out set is similar to unknown data, because the model has not \"seen\" it before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation via cross-validation\n",
    "\n",
    "One disadvantage of using a holdout set for model validation is that we have lost a portion of our data to the model training.\n",
    "In the above case, half the dataset does not contribute to the training of the model!\n",
    "This is not optimal, and can cause problems – especially if the initial set of training data is small.\n",
    "\n",
    "One way to address this is to use *cross-validation*; that is, to do a sequence of fits where each subset of the data is used both as a training set and as a validation set. Visually, it might look something like this:\n",
    "<img src= \"../images/2-fold-CV.png\" style=\"height: 500px;\">\n",
    "\n",
    "\n",
    "Here we do two validation trials, alternately using each half of the data as a holdout set.\n",
    "Using the split data from before, we could implement it like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "Write the code that implements the accuracy described on the previous image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9066666666666666, 0.96)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "y1_model = model.fit(X_train, y_train).predict(X_test)\n",
    "y2_model = model.fit(X_test, y_test).predict(X_train)\n",
    "accuracy_score(y_test, y1_model), accuracy_score(y_train, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What comes out are two accuracy scores, which we could combine (by, say, taking the mean) to get a better measure of the global model performance.\n",
    "This particular form of cross-validation is a *two-fold cross-validation*—that is, one in which we have split the data into two sets and used each in turn as a validation set.\n",
    "\n",
    "We could expand on this idea to use even more trials, and more folds in the data—for example, here is a visual depiction of five-fold cross-validation:\n",
    "\n",
    "<img src='../images/CV.png'/>\n",
    "\n",
    "Here we split the data into five groups, and use each of them in turn to evaluate the model fit on the other 4/5 of the data.\n",
    "This would be rather tedious to do by hand, and so we can use Scikit-Learn's ``cross_val_score`` convenience routine to do it succinctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96, 0.92])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model= KNeighborsClassifier(n_neighbors=3)\n",
    "scores = cross_val_score(model, X, y, cv=2)  \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the score computed at each cv iteration is the `score` method of the estimator. It is possible to change this by using the scoring parameter. Take a look at all possible values for [scoring parameter](https://scikit-learn.org/stable/modules/model_evaluation.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.95998399, 0.91987179]), 0.9399278942346169)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_f1 = cross_val_score(model, X, y, cv=2, scoring='f1_macro')   \n",
    "scores_f1, np.mean(scores_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating the validation across different subsets of the data gives us an even better idea of the performance of the algorithm.\n",
    "\n",
    "Scikit-Learn implements a number of useful cross-validation schemes that are useful in particular situations; these are implemented via iterators in the ``cross_validation`` module.\n",
    "For example, we might wish to go to the extreme case in which our number of folds is equal to the number of data points: that is, we train on all points but one in each trial.\n",
    "This type of cross-validation is known as *leave-one-out* cross validation, and can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "model= KNeighborsClassifier(n_neighbors=3)\n",
    "scores = cross_val_score(model, X, y, cv=LeaveOneOut())\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have 150 samples, the leave one out cross-validation yields scores for 150 trials, and the score indicates either successful (1.0) or unsuccessful (0.0) prediction.\n",
    "Taking the mean of these gives an estimate of the error rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other cross-validation schemes can be used similarly.\n",
    "For a description of what is available in Scikit-Learn, use IPython to explore the ``sklearn.cross_validation`` submodule, or take a look at Scikit-Learn's online [cross-validation documentation](http://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "Try to classify Iris data using KNN for n_neighbors=4. Use 5-fold cross validation and use Accuracy, Precision, Recall, F1-score as evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Accuracy: 0.9733333333333334\n",
      "Mean of Precision: 0.9757575757575758\n",
      "Mean of Recall: 0.9733333333333334\n",
      "Mean of F1_scores: 0.9732664995822891\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "\n",
    "knn_5= KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "A_scores=cross_val_score(knn_5, X, y, cv=5)\n",
    "A_mean=np.mean(A_scores)\n",
    "print('Mean of Accuracy: {}'.format(A_mean))\n",
    "\n",
    "P_scores=cross_val_score(knn_5, X, y, cv=5, scoring='precision_macro')\n",
    "P_mean=np.mean(P_scores)\n",
    "print('Mean of Precision: {}'.format(P_mean))\n",
    "\n",
    "R_scores=cross_val_score(knn_5, X, y, cv=5, scoring='recall_macro')\n",
    "R_mean=np.mean(R_scores)\n",
    "print('Mean of Recall: {}'.format(R_mean))\n",
    "\n",
    "F1_scores=cross_val_score(knn_5, X, y, cv=5, scoring='f1_macro')\n",
    "F1_mean=np.mean(F1_scores)\n",
    "print('Mean of F1_scores: {}'.format(F1_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Try to classify 'indian_liver_patient.csv' data using KNN for n_neighbors=5 and Logistic Regression. Use 3-fold cross validation.\n",
    "\n",
    "This data set contains 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh, India. The \"Dataset\" column is a class label used to divide groups into liver patient (liver disease) or not (no disease). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65  Female              0.7               0.1                   187   \n",
       "1   62    Male             10.9               5.5                   699   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0      3.3                        0.90        0  \n",
       "1      3.2                        0.74        0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver = pd.read_csv(\"../Data/indian_liver_patient.csv\")\n",
    "liver.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         583 non-null    int64  \n",
      " 1   Gender                      583 non-null    object \n",
      " 2   Total_Bilirubin             583 non-null    float64\n",
      " 3   Direct_Bilirubin            583 non-null    float64\n",
      " 4   Alkaline_Phosphotase        583 non-null    int64  \n",
      " 5   Alamine_Aminotransferase    583 non-null    int64  \n",
      " 6   Aspartate_Aminotransferase  583 non-null    int64  \n",
      " 7   Total_Protiens              583 non-null    float64\n",
      " 8   Albumin                     583 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio  583 non-null    float64\n",
      " 10  Dataset                     583 non-null    int64  \n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "liver.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    416\n",
       "1    167\n",
       "Name: Dataset, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assuming 0=no disease and 1=disease\n",
    "liver.Dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver.drop('Dataset', axis=1)\n",
    "y = liver.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>40</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>52</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>31</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0     65              0.7               0.1                   187   \n",
       "1     62             10.9               5.5                   699   \n",
       "2     62              7.3               4.1                   490   \n",
       "3     58              1.0               0.4                   182   \n",
       "4     72              3.9               2.0                   195   \n",
       "..   ...              ...               ...                   ...   \n",
       "578   60              0.5               0.1                   500   \n",
       "579   40              0.6               0.1                    98   \n",
       "580   52              0.8               0.2                   245   \n",
       "581   31              1.3               0.5                   184   \n",
       "582   38              1.0               0.3                   216   \n",
       "\n",
       "     Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                          16                          18             6.8   \n",
       "1                          64                         100             7.5   \n",
       "2                          60                          68             7.0   \n",
       "3                          14                          20             6.8   \n",
       "4                          27                          59             7.3   \n",
       "..                        ...                         ...             ...   \n",
       "578                        20                          34             5.9   \n",
       "579                        35                          31             6.0   \n",
       "580                        48                          49             6.4   \n",
       "581                        29                          32             6.8   \n",
       "582                        21                          24             7.3   \n",
       "\n",
       "     Albumin  Albumin_and_Globulin_Ratio  Gender_Male  \n",
       "0        3.3                        0.90            0  \n",
       "1        3.2                        0.74            1  \n",
       "2        3.3                        0.89            1  \n",
       "3        3.4                        1.00            1  \n",
       "4        2.4                        0.40            1  \n",
       "..       ...                         ...          ...  \n",
       "578      1.6                        0.37            1  \n",
       "579      3.2                        1.10            1  \n",
       "580      3.2                        1.00            1  \n",
       "581      3.4                        1.00            1  \n",
       "582      4.4                        1.50            1  \n",
       "\n",
       "[583 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dum=pd.get_dummies(X, drop_first=True)\n",
    "X_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of precision: 0.5797898665311592\n"
     ]
    }
   ],
   "source": [
    "### KNN\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_scaled = MinMaxScaler().fit_transform(X_dum)\n",
    "\n",
    "\n",
    "knn_5= KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "A_scores=cross_val_score(knn_5, x_scaled, y, cv=3, scoring='precision_macro')\n",
    "A_mean=np.mean(A_scores)\n",
    "print('Mean of precision: {}'.format(A_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of precision: 0.7758208345692875\n"
     ]
    }
   ],
   "source": [
    "### Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_5= LogisticRegression()\n",
    "\n",
    "A_scores=cross_val_score(lr_5, x_scaled, y, cv=3, scoring='precision_macro')\n",
    "A_mean=np.mean(A_scores)\n",
    "print('Mean of precision: {}'.format(A_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "Grid search is the process of performing hyper parameter tuning in order to determine the optimal values for a given model. Scikit-Learn provides automated tools to do this in the grid search module.\n",
    "\n",
    "Here is an example of using grid search to find the optimal KNN model. This can be set up using Scikit-Learn's ``GridSearchCV`` meta-estimator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load breast_cancer data that is available from sklearn datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = cancer.data\n",
    "y= cancer.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,random_state=42, train_size=.80,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 20),\n",
    "              'p': [1,2],\n",
    "              'weights': ['uniform','distance']}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), \n",
    "                    param_grid, scoring='precision_macro',\n",
    "                    cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the total number of models that grid search builds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that like a normal estimator, this has not yet been applied to any data.\n",
    "Calling the ``fit()`` method will fit the model at each grid point, keeping track of the scores along the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is fit, we can ask for the best parameters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                         'p': [1, 2], 'weights': ['uniform', 'distance']},\n",
       "             scoring='precision_macro')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if we wish, we can use the best model and show the fit to our data using code from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        42\n",
      "           1       0.95      0.97      0.96        72\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[38,  4],\n",
       "       [ 2, 70]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "print('classification_report:\\n',classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search provides many more options, including the ability to specify a custom scoring function, to parallelize the computations, to do randomized searches, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Load the cancer dataset and choose the best classification algorithm with the best hyperparameters.\n",
    "\n",
    "- Define X and y\n",
    "\n",
    "- To simplify, remove missing values\n",
    "\n",
    "- Split data to train and test\n",
    "\n",
    "- Use 5 fold cross validation and grid search on train data\n",
    "\n",
    "- Choose appropriate validation metric\n",
    "\n",
    "- Set grid parameters for each classification algorithm\n",
    "\n",
    "- Build the best models for each classification algorithm according to the best estimator (best hyperparameters) given by the grid search\n",
    "\n",
    "- Compare the performance of the algorithms with the best hyperparametrs on the test data according to confusion matrix, recall, precision, F1, and auc metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Cell.shape</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Cl.thickness  Cell.size  Cell.shape  Marg.adhesion  \\\n",
       "0    1000025             5          1           1              1   \n",
       "1    1002945             5          4           4              5   \n",
       "2    1015425             3          1           1              1   \n",
       "3    1016277             6          8           8              1   \n",
       "4    1017023             4          1           1              3   \n",
       "..       ...           ...        ...         ...            ...   \n",
       "694   776715             3          1           1              1   \n",
       "695   841769             2          1           1              1   \n",
       "696   888820             5         10          10              3   \n",
       "697   897471             4          8           6              4   \n",
       "698   897471             4          8           8              5   \n",
       "\n",
       "     Epith.c.size  Bare.nuclei  Bl.cromatin  Normal.nucleoli  Mitoses  Class  \n",
       "0               2          1.0            3                1        1      0  \n",
       "1               7         10.0            3                2        1      0  \n",
       "2               2          2.0            3                1        1      0  \n",
       "3               3          4.0            3                7        1      0  \n",
       "4               2          1.0            3                1        1      0  \n",
       "..            ...          ...          ...              ...      ...    ...  \n",
       "694             3          2.0            1                1        1      0  \n",
       "695             2          1.0            1                1        1      0  \n",
       "696             7          3.0            8               10        2      1  \n",
       "697             3          4.0           10                6        1      1  \n",
       "698             4          5.0           10                4        1      1  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/breast_cancer_wisconsin.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Cell.shape</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Cl.thickness  Cell.size  Cell.shape  Marg.adhesion  Epith.c.size  \\\n",
       "0  1000025             5          1           1              1             2   \n",
       "1  1002945             5          4           4              5             7   \n",
       "2  1015425             3          1           1              1             2   \n",
       "3  1016277             6          8           8              1             3   \n",
       "4  1017023             4          1           1              3             2   \n",
       "\n",
       "   Bare.nuclei  Bl.cromatin  Normal.nucleoli  Mitoses  Class  \n",
       "0          1.0            3                1        1      0  \n",
       "1         10.0            3                2        1      0  \n",
       "2          2.0            3                1        1      0  \n",
       "3          4.0            3                7        1      0  \n",
       "4          1.0            3                1        1      0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MC\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                 0\n",
      "Cl.thickness       0\n",
      "Cell.size          0\n",
      "Cell.shape         0\n",
      "Marg.adhesion      0\n",
      "Epith.c.size       0\n",
      "Bare.nuclei        0\n",
      "Bl.cromatin        0\n",
      "Normal.nucleoli    0\n",
      "Mitoses            0\n",
      "Class              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "print(df.isna().sum())\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Cell.shape</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cl.thickness  Cell.size  Cell.shape  Marg.adhesion  Epith.c.size  \\\n",
       "0             5          1           1              1             2   \n",
       "1             5          4           4              5             7   \n",
       "2             3          1           1              1             2   \n",
       "3             6          8           8              1             3   \n",
       "4             4          1           1              3             2   \n",
       "\n",
       "   Bare.nuclei  Bl.cromatin  Normal.nucleoli  Mitoses  \n",
       "0          1.0            3                1        1  \n",
       "1         10.0            3                2        1  \n",
       "2          2.0            3                1        1  \n",
       "3          4.0            3                7        1  \n",
       "4          1.0            3                1        1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MC\n",
    "X = df.drop(['Id','Class'], axis=1)\n",
    "y = df.Class\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    444\n",
       "1    239\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MC\n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MC\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Cell.shape</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.442167</td>\n",
       "      <td>3.150805</td>\n",
       "      <td>3.215227</td>\n",
       "      <td>2.830161</td>\n",
       "      <td>3.234261</td>\n",
       "      <td>3.544656</td>\n",
       "      <td>3.445095</td>\n",
       "      <td>2.869693</td>\n",
       "      <td>1.603221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.820761</td>\n",
       "      <td>3.065145</td>\n",
       "      <td>2.988581</td>\n",
       "      <td>2.864562</td>\n",
       "      <td>2.223085</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>2.449697</td>\n",
       "      <td>3.052666</td>\n",
       "      <td>1.732674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cl.thickness   Cell.size  Cell.shape  Marg.adhesion  Epith.c.size  \\\n",
       "count    683.000000  683.000000  683.000000     683.000000    683.000000   \n",
       "mean       4.442167    3.150805    3.215227       2.830161      3.234261   \n",
       "std        2.820761    3.065145    2.988581       2.864562      2.223085   \n",
       "min        1.000000    1.000000    1.000000       1.000000      1.000000   \n",
       "25%        2.000000    1.000000    1.000000       1.000000      2.000000   \n",
       "50%        4.000000    1.000000    1.000000       1.000000      2.000000   \n",
       "75%        6.000000    5.000000    5.000000       4.000000      4.000000   \n",
       "max       10.000000   10.000000   10.000000      10.000000     10.000000   \n",
       "\n",
       "       Bare.nuclei  Bl.cromatin  Normal.nucleoli     Mitoses  \n",
       "count   683.000000   683.000000       683.000000  683.000000  \n",
       "mean      3.544656     3.445095         2.869693    1.603221  \n",
       "std       3.643857     2.449697         3.052666    1.732674  \n",
       "min       1.000000     1.000000         1.000000    1.000000  \n",
       "25%       1.000000     2.000000         1.000000    1.000000  \n",
       "50%       1.000000     3.000000         1.000000    1.000000  \n",
       "75%       6.000000     5.000000         4.000000    1.000000  \n",
       "max      10.000000    10.000000        10.000000   10.000000  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MC\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=.8,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn Best parameters {'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n",
      "Knn best score =  0.9940848871908916\n",
      "Knn best model confusion matrix on test data  \n",
      " [[87  2]\n",
      " [ 0 48]]\n",
      "*********************************************\n",
      "Knn best model Precision  on test data = 0.96\n",
      "Knn best model Recall  on test data = 1.00\n",
      "Knn best model F1 on test data = 0.98\n",
      "Knn best model Accuracy  on test data = 0.99\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "knn_param_grid = {'n_neighbors': np.arange(1, 30),\n",
    "                  'p': [1,2],\n",
    "                 'weights':['uniform','distance']}\n",
    "                   \n",
    "\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), \n",
    "                        knn_param_grid, cv=5, scoring = 'roc_auc', return_train_score=True)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "print('Knn Best parameters', knn_grid.best_params_)\n",
    "knn_model = knn_grid.best_estimator_\n",
    "knn_model.fit(X_train, y_train)\n",
    "print('Knn best score = ',knn_grid.best_score_ )\n",
    "\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "print('Knn best model confusion matrix on test data  \\n',confusion_matrix(y_test, knn_pred)  )\n",
    "print('*********************************************')\n",
    "print('Knn best model Precision  on test data = {:.2f}'.format(precision_score(y_test, knn_pred)))\n",
    "print('Knn best model Recall  on test data = {:.2f}'.format(recall_score(y_test, knn_pred)))\n",
    "print('Knn best model F1 on test data = {:.2f}'.format(f1_score(y_test, knn_pred)))\n",
    "print('Knn best model Accuracy  on test data = {:.2f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('*********************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecosionTree Best parameters {'max_depth': 3}\n",
      "DecosionTree best score =  0.957172454429682\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "dt_param_grid = {'max_depth': np.arange(1, 10)}\n",
    "\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=1), \n",
    "                        dt_param_grid, cv=5, scoring = 'roc_auc', return_train_score=True)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "print('DecosionTree Best parameters', dt_grid.best_params_)\n",
    "dt_model = dt_grid.best_estimator_\n",
    "print('DecosionTree best score = ',dt_grid.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Best parameters {'C': 100, 'fit_intercept': True, 'penalty': 'l2'}\n",
      "LogisticRegression best score =  0.9956530003231265\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "logr_param_grid = {'C': [0.001, 0.004, 0.01, 0.1, 0.4, 1, 10, 50, 100],\n",
    "                   'penalty' : ['l1', 'l2'],\n",
    "                   'fit_intercept': [True, False]}\n",
    "\n",
    "logr_grid = GridSearchCV(LogisticRegression(solver='liblinear'), \n",
    "                        logr_param_grid, cv=5, scoring = 'roc_auc', return_train_score=True)\n",
    "logr_grid.fit(X_train, y_train)\n",
    "print('LogisticRegression Best parameters', logr_grid.best_params_)\n",
    "logr_model = logr_grid.best_estimator_\n",
    "print('LogisticRegression best score = ',logr_grid.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Best parameters {'C': 0.001, 'degree': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "LogisticRegression best score =  0.996082568284199\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "svc_param_grid = {'C': [0.001, 0.004, 0.01, 0.1, 0.4, 1, 10, 50, 100],\n",
    "                  'kernel' : ['linear', 'rbf'],\n",
    "                  'gamma': [0.001, 0.004, 0.01, 0.1, 0.4, 1, 10, 50, 100]}\n",
    "\n",
    "svc_grid = GridSearchCV(SVC(), \n",
    "                        svc_param_grid, cv=5, scoring = 'roc_auc', return_train_score=True)\n",
    "svc_grid.fit(X_train, y_train)\n",
    "print('LogisticRegression Best parameters', svc_grid.best_params_)\n",
    "svc_model = svc_grid.best_estimator_\n",
    "print('LogisticRegression best score = ',svc_grid.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PipeLine: Polynomial Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(include_bias=False)),\n",
       "                ('minmaxscaler', MinMaxScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False), \n",
    "    MinMaxScaler(), \n",
    "    LogisticRegression())\n",
    "\n",
    "poly_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Polynomial Best parameters {'logisticregression__C': 1, 'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear', 'polynomialfeatures__degree': 3}\n",
      "LogisticRegression Polynomial best score =  0.9963087567238791\n"
     ]
    }
   ],
   "source": [
    "#MC\n",
    "pip_param_grid = {'polynomialfeatures__degree':[1,2,3],\n",
    "                  'logisticregression__C': [0.001, 0.004, 0.01, 0.1, 0.4, 1, 10, 50, 100],\n",
    "                   'logisticregression__penalty' : ['l1', 'l2'],\n",
    "                   'logisticregression__solver': ['liblinear'],\n",
    "                   'logisticregression__fit_intercept': [True, False]}\n",
    "pip_grid = GridSearchCV(poly_pipeline, \n",
    "                        pip_param_grid, cv=5, scoring = 'roc_auc', return_train_score=True)\n",
    "pip_grid.fit(X_train, y_train)\n",
    "print('LogisticRegression Polynomial Best parameters', pip_grid.best_params_)\n",
    "pip_model = pip_grid.best_estimator_\n",
    "print('LogisticRegression Polynomial best score = ',pip_grid.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the best models on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn best model confusion matrix on test data  \n",
      " [[87  2]\n",
      " [ 0 48]]\n",
      "*********************************************\n",
      "Knn best model Precision  on test data = 0.96\n",
      "Knn best model Recall  on test data = 1.00\n",
      "Knn best model F1 on test data = 0.98\n",
      "Knn best model Accuracy  on test data = 0.99\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "print('Knn best model confusion matrix on test data  \\n',confusion_matrix(y_test, knn_pred)  )\n",
    "print('*********************************************')\n",
    "print('Knn best model Precision  on test data = {:.2f}'.format(precision_score(y_test, knn_pred)))\n",
    "print('Knn best model Recall  on test data = {:.2f}'.format(recall_score(y_test, knn_pred)))\n",
    "print('Knn best model F1 on test data = {:.2f}'.format(f1_score(y_test, knn_pred)))\n",
    "print('Knn best model Accuracy  on test data = {:.2f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('*********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree best model confusion matrix on test data  \n",
      " [[85  4]\n",
      " [ 2 46]]\n",
      "*********************************************\n",
      "Decision Tree best model Precision  on test data = 0.92\n",
      "Decision Tree best model Recall on test data = 0.96\n",
      "Decision Tree best model F1 on test data  = 0.94\n",
      "Decision Tree best model Accuracy  on test data = 0.96\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "print('Decision Tree best model confusion matrix on test data  \\n',confusion_matrix(y_test, dt_pred)  )\n",
    "print('*********************************************')\n",
    "print('Decision Tree best model Precision  on test data = {:.2f}'.format(precision_score(y_test, dt_pred)))\n",
    "print('Decision Tree best model Recall on test data = {:.2f}'.format(recall_score(y_test, dt_pred)))\n",
    "print('Decision Tree best model F1 on test data  = {:.2f}'.format(f1_score(y_test, dt_pred)))\n",
    "print('Decision Tree best model Accuracy  on test data = {:.2f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('*********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best model confusion matrix on test data  \n",
      " [[87  2]\n",
      " [ 0 48]]\n",
      "*********************************************\n",
      "Logistic Regression best model Precision  on test data = 0.96\n",
      "Logistic Regression best model Recall on test data = 1.00\n",
      "Logistic Regression best model F1 on test data  = 0.98\n",
      "Logistic Regression best model Accuracy  on test data = 0.99\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "logr_pred = logr_model.predict(X_test)\n",
    "print('Logistic Regression best model confusion matrix on test data  \\n',confusion_matrix(y_test, logr_pred)  )\n",
    "print('*********************************************')\n",
    "print('Logistic Regression best model Precision  on test data = {:.2f}'.format(precision_score(y_test, logr_pred)))\n",
    "print('Logistic Regression best model Recall on test data = {:.2f}'.format(recall_score(y_test, logr_pred)))\n",
    "print('Logistic Regression best model F1 on test data  = {:.2f}'.format(f1_score(y_test, logr_pred)))\n",
    "print('Logistic Regression best model Accuracy  on test data = {:.2f}'.format(accuracy_score(y_test, logr_pred)))\n",
    "print('*********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC best model confusion matrix on test data  \n",
      " [[87  2]\n",
      " [ 1 47]]\n",
      "*********************************************\n",
      "SVC best model Precision  on test data = 0.96\n",
      "SVC best model Recall on test data = 0.98\n",
      "SVC best model F1 on test data  = 0.97\n",
      "SVC best model Accuracy  on test data = 0.98\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "svc_pred = svc_model.predict(X_test)\n",
    "print('SVC best model confusion matrix on test data  \\n',confusion_matrix(y_test, svc_pred)  )\n",
    "print('*********************************************')\n",
    "print('SVC best model Precision  on test data = {:.2f}'.format(precision_score(y_test, svc_pred)))\n",
    "print('SVC best model Recall on test data = {:.2f}'.format(recall_score(y_test, svc_pred)))\n",
    "print('SVC best model F1 on test data  = {:.2f}'.format(f1_score(y_test, svc_pred)))\n",
    "print('SVC best model Accuracy  on test data = {:.2f}'.format(accuracy_score(y_test, svc_pred)))\n",
    "print('*********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip best model confusion matrix on test data  \n",
      " [[87  2]\n",
      " [ 0 48]]\n",
      "*********************************************\n",
      "pip best model Precision  on test data = 0.96\n",
      "pip best model Recall on test data = 1.00\n",
      "pip best model F1 on test data  = 0.98\n",
      "pip best model Accuracy  on test data = 0.99\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "# MC\n",
    "pip_pred = pip_model.predict(X_test)\n",
    "print('pip best model confusion matrix on test data  \\n',confusion_matrix(y_test, pip_pred)  )\n",
    "print('*********************************************')\n",
    "print('pip best model Precision  on test data = {:.2f}'.format(precision_score(y_test, pip_pred)))\n",
    "print('pip best model Recall on test data = {:.2f}'.format(recall_score(y_test, pip_pred)))\n",
    "print('pip best model F1 on test data  = {:.2f}'.format(f1_score(y_test, pip_pred)))\n",
    "print('pip best model Accuracy  on test data = {:.2f}'.format(accuracy_score(y_test, pip_pred)))\n",
    "print('*********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
